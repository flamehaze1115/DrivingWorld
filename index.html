<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <style>
    /* 用于控制图片大小和居中显示 */
    .carousel-image {
      display: block;
      margin-left: auto;
      margin-right: auto;
      max-width: 60%; /* 容器宽度的100%，根据需要调整 */
      height: auto; /* 维持图像的宽高比 */
    }
    
    /* 用于垂直居中 .item 内的内容 */
    .item {
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      text-align: center;
      height: 100%; /* 根据需要调整高度 */
    }
    
    .my-image-size {
      width: 90%; /* or any other fixed size like 300px */
     
    
     
  }

  .mb-5 {
    margin-bottom: 5rem; /* or any other value you prefer */
}

      </style>

  <title>DrivingWorld</title> 
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title"> <a style="color:#D46EE8">DrivingWorld</a>:  Constructing World Model for Autonomous Driving via Video GPT</h1>
            <!-- <div class="is-size-5 publication-authors"> -->
              <!-- Paper authors -->
              <!-- <span class="author-block">
                <a href="https://huxiaotaostasy.github.io/" target="_blank">Xiaotao Hu<sup>1,2,*</sup></a>,</span>
                <span class="author-block"> -->

                <!-- <a href="https://yvanyin.net/" target="_blank">Wei Yin<sup>2,*</sup></a>,</span>
                <span class="author-block">

                <a href="https://scholar.google.com/citations?user=fcpTdvcAAAAJ&hl=en&oi=ao" target="_blank">Mingkai Jia<sup>1,2</sup></a>,</span>
                <span class="author-block">

                <a href="#" target="_blank">Junyuan Deng<sup>1,2</sup></a>,</span>
                <span class="author-block">

                <a href="https://scholar.google.com/citations?user=CrK4w4UAAAAJ&hl=en&oi=ao" target="_blank">Xiaoyang Guo<sup>2</sup></a>,</span>
                <span class="author-block">

                <a href="https://scholar.google.com/citations?hl=en&user=pCY-bikAAAAJ" target="_blank">Qian Zhang<sup>2</sup></a>,</span>
                <span class="author-block">

                <a href="https://www.xxlong.site/" target="_blank">Xiaoxiao Long<sup>1,†</sup></a>,</span>
                <span class="author-block">

                <a href="https://scholar.google.com/citations?user=XhyKVFMAAAAJ&hl=en&oi=ao" target="_blank">Ping Tan<sup>1</sup></a></span>
                <span class="author-block">

                </div> -->

                  <!-- <div class="is-size-5 publication-authors">
                    <span class="author-block">
                      <sup>1</sup> Hong Kong University of Science and Technology |  <sup>2</sup>Horizon Robotics <br>
                    </span>
                    <span class="eql-cntrb">
                      <small><br><sup>*</sup>denotes equal contribution | </small>
                      <small><sup>†</sup>denotes Corresponding authors</small>
                    </span>
                  </div> -->
                  

                  <!-- <div class="column has-text-centered">
                    <div class="publication-links"> -->
                         <!-- Arxiv PDF link -->
                      <!-- <span class="link-block">
                        <a href="#" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span> -->

                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block">
                      <a href="http://www.semantic-kitti.org/" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-database"></i>
                      </span>
                      <span>Dataset</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <!-- <span class="link-block">
                    <a href="#" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span> -->

                <!-- ArXiv abstract Link -->
                <!-- <span class="link-block">
                  <a href="#" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-file-video"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body"> -->
      <!-- <video poster="" id="tree" autoplay controls muted loop height="100%">
        <source src="static/videos/output.mp4"
        type="video/mp4">
      </video> -->
      <!-- <br>
      <br>
      <br> -->
      <!-- <h2 class="subtitle has-text-left">
        <p>An example of controllable generation. We design two trajectories for the same scene to generate different driving scenarios, <em>i.e.</em>, one moving straight forward and the other with a curved path.</p>
      </h2> -->
      <!--div class="columns is-centered mb-6">
        <div class="column is-full has-text-centered">
          <img class="my-image-size" src="static/images/2.png" alt="Overview Image">
          <h3 class="subtitle" style="font-size: 1.5rem; font-weight: normal;color:#D46EE8;">Comparison of Performance (i.e. collision rate), Efficiency (i.e. FPS), and Comfort Metrics</h3>
        </div>
      </div-->


    <!-- </div>
  </div>
</section> -->
<!-- End teaser video -->

<!-- Paper abstract -->
<!-- <section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Recent successes in autoregressive (AR) generation models, such as the GPT series in natural language processing, have motivated efforts to replicate this success in visual tasks. 
            Some research aims to extend this approach to autonomous driving by building video-based world models capable of generating realistic future video sequences and predicting the ego states.
            However, the prior works tend to produce unsatisfactory results, since the classic GPT framework is designed to handle 1D contextual information, such as text, and lacks the inherent capability to model the spatial and temporal dynamics necessary for video generation.
            </p>
            
            <p>
            In this paper, we present DrivingWorld, a GPT-style world model for autonomous driving with several spatial-temporal fusion mechanisms. This design allows for effective modeling of both spatial and temporal dynamics, enabling high-fidelity, long time video generation.
            Specifically, we first propose next-state-prediction strategy to model temporal coherence between consecutive frames and then apply next-token-prediction strategy to capture spatial information within a frame. To further enhance generalization ability, we propose a novel masking strategy and reweight strategy for token prediction to mitigate long time drifting issues and enable precise control.
            Our work is capable of producing high-fidelity and consistent video clips with long-time duration. 
            </p>
            
            <p>
            Experiments demonstrate that, in contrast to prior works, our method delivers superior visual quality and significantly more accurate controllable future video generation.
            </p>
             <br>
          </div>
      </div>
    </div>
  </div> -->




<!-- <section class="section hero is-white">
  <div class="container is-max-desktop"> -->

    <!-- Row 1: Overview -->
    <!-- <div class="columns is-centered mb-6">
      <div class="column is-full has-text-centered">
        <img class="my-image-size" src="static/images/pipeline-1.png" alt="Overview Image">
        <h3 class="subtitle" style="font-size: 1.5rem; font-weight: normal;color:#D46EE8;">DrivingWorld Overview</h3>
      </div>
    </div>
    <br> -->
    <!-- Row Title: OccRWKV Key Components -->
    <!-- <div class="columns is-centered">
      <div class="column is-full">
        <h2 class="title is-3">The World Model Component</h2>
      </div>
    </div> -->

    

    <!-- Row 2: Block -->
    <!-- <div class="columns is-centered mb-6">
      <div class="column is-full has-text-centered">
        <img class="my-image-size" src="static/images/structure-1.png" alt="Block Image">
        <h3 class="subtitle" style="font-size: 1.5rem; font-weight: normal;color:#D46EE8;"> Inference Illustration of Vanilla GPT and Temporal-aware GPT (Ours).</h3>
      </div>
    </div>
    <br> -->


  <!-- </div> 
</section> -->

<section class="section hero is-light">
  <div class="container is-max-desktop">

    <!-- Row Title: OccRWKV Key Components -->
    <div class="columns is-centered">
      <div class="column is-full">
        <h2 class="title is-3">Experiment 1: Controllable Generation</h2>
      </div>
    </div>

    <!-- <p>
      In following examples, we designed multiple trajectories for the ego car, which can generate different driving scenarios.
    </p> -->
    <h2 style="margin-top: 10px;" class="subtitle has-text-left">
      <p>In following examples, we designed multiple trajectories for the ego car, which can generate different driving scenarios.</p>
    </h2>

    <!-- Two Columns for Parallel Display -->
    <div class="columns is-centered mb-6">
        <body>
          <video style="padding-top: 50px;" poster="" id="tree" autoplay controls muted loop height="100%">
            <source src="static/videos/only_turn_left_trajectory.mp4"
            type="video/mp4">
          </video>
        </body>
    </div>

    <h2 style="margin-top: 1px;" class="subtitle has-text-left">
      <p>Example 1: We design the trajectory, which moving straight foward first, and then turn left to the left lane.</p>
    </h2>

    <div class="columns is-centered mb-6">
      <body>
        <video poster="" id="tree" autoplay controls muted loop height="100%">
          <!-- Your video here -->
          <source src="static/videos/only_turn_right_trajectory.mp4"
          type="video/mp4">
        </video>
      </body>
  </div>
  
  <h2 class="subtitle has-text-left">
    <p>Example 2: We design the trajectory, which moving straight foward first, and then turn right to the right lane.</p>
  </h2>

  <div class="columns is-centered mb-6">
    <body>
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <!-- Your video here -->
        <source src="static/videos/only_turn_left_and_left_trajectory.mp4"
        type="video/mp4">
      </video>
    </body>
</div>

<h2 class="subtitle has-text-left">
  <p>Example 3: The car is designed to drive in a curved path, which turn left twice to its left lane.</p>
</h2>

<div class="columns is-centered mb-6">
  <body>
    <video poster="" id="tree" autoplay controls muted loop height="100%">
      <!-- Your video here -->
      <source src="static/videos/only_turn_left_right_trajectory.mp4"
      type="video/mp4">
    </video>
  </body>
</div>

<h2 class="subtitle has-text-left">
<p>Example 4: The car is designed to drive in a curved path, which turn left first and then turn right.</p>
</h2>

<div class="columns is-centered mb-6">
  <body>
    <video poster="" id="tree" autoplay controls muted loop height="100%">
      <!-- Your video here -->
      <source src="static/videos/only_turn_right_left_trajectory.mp4"
      type="video/mp4">
    </video>
  </body>
</div>

<h2 class="subtitle has-text-left">
<p>Example 5: The ego car is designed to turn right to the right lane and then turn left to the original lane.</p>
</h2>

  </div>
</section>


<section class="section hero is-light">
  <div class="container is-max-desktop">

    <!-- Row Title: OccRWKV Key Components -->
    <div class="columns is-centered">
      <div class="column is-full">
        <h2 class="title is-3">Experiment 2: Long-term Generation</h2>
      </div>
    </div>

    <!-- <p>
      In following examples, we present multiple different long-term generations. Each generated videos contains over 600 frames.
    </p> -->
    <h2 style="margin-top: 10px;" class="subtitle has-text-left">
      <p>In following examples, we present multiple different long-term generations. Each generated videos contains over 600 frames.</p>
    </h2>

    <!-- Two Columns for Parallel Display -->
    <!-- <div class="columns is-centered mb-6"> -->
        <!-- <body> -->
          <!-- <video poster="" id="tree" autoplay controls muted loop height="100%"> -->
            <!-- Your video here -->
            <!-- <source src="static/videos/long_term_1.mp4"
            type="video/mp4"> -->
          <!-- </video> -->
        <!-- </body> -->
    <!-- </div> -->

    <!-- <h2 class="subtitle has-text-left"> -->
      <!-- <p></p> -->
    <!-- </h2> -->


<div class="columns is-centered mb-6">
  <body>
    <video style="margin-top: 10px;"  poster="" id="tree" autoplay controls muted loop height="100%">
      <!-- Your video here -->
      <source src="static/videos/long_term_4.mp4"
      type="video/mp4">
    </video>
  </body>
</div>

<!-- <h2 class="subtitle has-text-left"> -->
<!-- <p>An example of controllable generation. We design two trajectories for the same scene to generate different driving scenarios, <em>i.e.</em>, one moving straight forward and the other with a curved path.</p> -->
<!-- </h2> -->


<div class="columns is-centered mb-6">
  <body>
    <video poster="" id="tree" autoplay controls muted loop height="100%">
      <!-- Your video here -->
      <source src="static/videos/long_term_2.mp4"
      type="video/mp4">
    </video>
  </body>
</div>

<!-- <h2 class="subtitle has-text-left"> -->
<!-- <p>An example of controllable generation. We design two trajectories for the same scene to generate different driving scenarios, <em>i.e.</em>, one moving straight forward and the other with a curved path.</p> -->
<!-- </h2> -->

<div class="columns is-centered mb-6">
<body>
  <video poster="" id="tree" autoplay controls muted loop height="100%">
    <!-- Your video here -->
    <source src="static/videos/long_term_3.mp4"
    type="video/mp4">
  </video>
</body>
</div>

<!-- <h2 class="subtitle has-text-left"> -->
<!-- <p>An example of controllable generation. We design two trajectories for the same scene to generate different driving scenarios, <em>i.e.</em>, one moving straight forward and the other with a curved path.</p> -->
<!-- </h2> -->

  </div>
</section>



<!--BibTex citation -->
<!-- <section class="section is-white" id="BibTeX" >
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
      @article{wang2024occrwkv,
        title={OccRWKV: Rethinking Efficient 3D Semantic Occupancy Prediction with Linear Complexity},
        author={Wang, Junming and Yin, Wei and Long, Xiaoxiao and Zhang, Xinyu and Xing, Zebing and Guo, Xiaoyang and Qian, Zhang},
        year={2024}
              } 
  </code></pre>
  </div>
</section> -->
<!--End BibTex citation -->


  <!-- <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer> -->

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
